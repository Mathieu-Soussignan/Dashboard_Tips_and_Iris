import streamlit as st
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import accuracy_score, f1_score, r2_score
import matplotlib.pyplot as plt
import plotly.express as px
import time

# CrÃ©ation d'un Dashboard multi-pages avec Streamlit
st.set_page_config(page_title="Machine Learning Dashboard", layout="wide", initial_sidebar_state="expanded")
st.sidebar.title("Navigation")
page = st.sidebar.radio("Aller Ã ", ["ğŸ  Partie 1 : PrÃ©paration des DonnÃ©es", "ğŸ“Š Partie 2 : Analyse des DonnÃ©es"])

# Image de couverture
st.image("./assets/machine_learning.jpg", caption="L'art de l'analyse de donnÃ©es !", use_column_width=True)

# Charger les donnÃ©es une fois
if page == "ğŸ  Partie 1 : PrÃ©paration des DonnÃ©es" or page == "ğŸ“Š Partie 2 : Analyse des DonnÃ©es":
    if page == "ğŸ  Partie 1 : PrÃ©paration des DonnÃ©es":
        data = sns.load_dataset('tips')
    elif page == "ğŸ“Š Partie 2 : Analyse des DonnÃ©es":
        data = sns.load_dataset('iris')

# Partie 1 : PrÃ©paration des DonnÃ©es
def partie_1(data):
    st.title("ğŸ  Partie 1 : PrÃ©paration des DonnÃ©es")

    # Afficher les premiÃ¨res lignes
    with st.expander("ğŸ‘€ AperÃ§u des premiÃ¨res lignes du dataset 'tips'"):
        st.dataframe(data.head())

    # Progress bar pour l'encodage des donnÃ©es
    with st.spinner("Encodage des variables catÃ©gorielles..."):
        columns_to_encode = ['sex', 'day', 'smoker', 'time']
        label_encoder = LabelEncoder()
        for column in columns_to_encode:
            data[column] = label_encoder.fit_transform(data[column])
        st.success("Encodage terminÃ©!")

    # Visualisation des donnÃ©es aprÃ¨s encodage
    st.subheader("ğŸ“Š DonnÃ©es aprÃ¨s encodage des variables catÃ©gorielles")
    st.write(data.head())

    # Affichage des donnÃ©es numÃ©riques
    df_numeric = data.select_dtypes(include=['int64', 'float64'])
    st.subheader("ğŸ”¢ DonnÃ©es numÃ©riques")
    st.write(df_numeric.head())

    # ConcatÃ©ner les donnÃ©es encodÃ©es avec les colonnes numÃ©riques
    df = pd.concat([data, df_numeric], axis=1).loc[:, ~pd.concat([data, df_numeric], axis=1).columns.duplicated()]
    st.subheader("ğŸ—‚ï¸ DonnÃ©es concatÃ©nÃ©es")
    st.write(df.head())

    # EntraÃ®nement du modÃ¨le de rÃ©gression linÃ©aire avec animation
    st.subheader("ğŸ“ˆ EntraÃ®nement du modÃ¨le de rÃ©gression linÃ©aire")
    X = df.drop(columns=['tip'])  # PrÃ©dicteurs
    y = df['tip']  # Variable cible

    model = LinearRegression()
    start_time = time.time()
    with st.spinner('EntraÃ®nement du modÃ¨le...'):
        model.fit(X, y)
    end_time = time.time()

    # Mesurer le temps d'entraÃ®nement
    training_time = end_time - start_time
    st.success(f"Temps d'entraÃ®nement du modÃ¨le : {training_time:.4f} secondes")

    # Ã‰valuation du modÃ¨le
    y_pred = model.predict(X)
    r2 = r2_score(y, y_pred)
    st.metric(label="ğŸ“Š Score RÂ² du modÃ¨le", value=f"{r2:.4f}")

# Partie 2 : Analyse des DonnÃ©es
def partie_2(data):
    st.title("ğŸ“Š Partie 2 : Analyse des DonnÃ©es du Dataset Iris")

    # AperÃ§u des premiÃ¨res lignes
    with st.expander("ğŸ‘€ AperÃ§u des premiÃ¨res lignes du dataset 'iris'"):
        st.dataframe(data.head())

    # Encodage de la variable 'species'
    with st.spinner("Encodage de la variable 'species'..."):
        label_encoder = LabelEncoder()
        data['species_encoded'] = label_encoder.fit_transform(data['species'])
    st.success("Encodage terminÃ©!")

    # Visualisation des histogrammes des features
    st.subheader("ğŸ“Š Histogrammes des Features")
    features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
    for feature in features:
        fig = px.histogram(data, x=feature, nbins=20, title=f"Histogramme de {feature}", template="plotly_dark")
        st.plotly_chart(fig)

    # Standardiser les features
    st.subheader("ğŸ”„ Standardisation des Features")
    scaler = StandardScaler()
    features_to_standardize = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
    data[features_to_standardize] = scaler.fit_transform(data[features_to_standardize])
    st.write(data.head())

    # EntraÃ®nement du modÃ¨le de rÃ©gression logistique
    st.subheader("ğŸ“ˆ EntraÃ®nement du modÃ¨le de RÃ©gression Logistique")
    df_train, df_test = train_test_split(data, test_size=0.2, random_state=42)
    X_train = df_train.iloc[:, 0:-2]  # Toutes les colonnes sauf la cible et la colonne encodÃ©e
    y_train = df_train['species_encoded']
    X_test = df_test.iloc[:, 0:-2]
    y_test = df_test['species_encoded']

    clf = LogisticRegression(max_iter=1000)
    start_time = time.time()
    with st.spinner('EntraÃ®nement du modÃ¨le...'):
        clf.fit(X_train, y_train)
    end_time = time.time()

    # Temps d'entraÃ®nement
    training_time = end_time - start_time
    st.success(f"Temps d'entraÃ®nement du modÃ¨le : {training_time:.4f} secondes")

    # PrÃ©dictions et mÃ©triques de performance
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')

    # Afficher les mÃ©triques sous forme de cartes
    st.subheader("ğŸ“Š Performance du modÃ¨le")
    col1, col2 = st.columns(2)
    col1.metric(label="ğŸ¯ PrÃ©cision", value=f"{accuracy:.4f}")
    col2.metric(label="ğŸ¯ Score F1 (weighted)", value=f"{f1:.4f}")

# Affichage des pages
if page == "ğŸ  Partie 1 : PrÃ©paration des DonnÃ©es":
    partie_1(data)
elif page == "ğŸ“Š Partie 2 : Analyse des DonnÃ©es":
    partie_2(data)